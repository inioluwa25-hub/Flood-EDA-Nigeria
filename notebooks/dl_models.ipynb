{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.16.2 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (2.16.2)\n",
      "Requirement already satisfied: numpy==1.26.4 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (2.3.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: matplotlib in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (3.10.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from tensorflow==2.16.2) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from tensorflow==2.16.2) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from tensorflow==2.16.2) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from tensorflow==2.16.2) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from tensorflow==2.16.2) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from tensorflow==2.16.2) (3.14.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from tensorflow==2.16.2) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from tensorflow==2.16.2) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from tensorflow==2.16.2) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from tensorflow==2.16.2) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from tensorflow==2.16.2) (4.25.8)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from tensorflow==2.16.2) (2.32.4)\n",
      "Requirement already satisfied: setuptools in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from tensorflow==2.16.2) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from tensorflow==2.16.2) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from tensorflow==2.16.2) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from tensorflow==2.16.2) (4.14.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from tensorflow==2.16.2) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from tensorflow==2.16.2) (1.73.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from tensorflow==2.16.2) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from tensorflow==2.16.2) (3.10.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (2025.6.15)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2) (3.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2) (3.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow==2.16.2) (0.45.1)\n",
      "Requirement already satisfied: rich in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow==2.16.2) (14.0.0)\n",
      "Requirement already satisfied: namex in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow==2.16.2) (0.1.0)\n",
      "Requirement already satisfied: optree in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow==2.16.2) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.2) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.2) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.2) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.2) (0.1.2)\n",
      "TF: 2.16.2, NumPy: 1.26.4\n"
     ]
    }
   ],
   "source": [
    "# Install with retries and connection handling\n",
    "!pip install --retries 10 --timeout 100 \\\n",
    "    tensorflow==2.16.2 \\\n",
    "    numpy==1.26.4 \\\n",
    "    pandas \\\n",
    "    scikit-learn \\\n",
    "    matplotlib\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "print(f\"TF: {tf.__version__}, NumPy: {np.__version__}\")  # Verify TF 2.16.2 and NumPy 1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.16.2, NumPy: 1.26.4\n"
     ]
    }
   ],
   "source": [
    "# Import these libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Conv1D, MaxPooling1D, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"TensorFlow: {tf.__version__}, NumPy: {np.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting preprocessor...\n",
      "✅ Preprocessor saved to ../models/preprocessor.joblib\n",
      "✅ Data preparation complete!\n",
      "Shapes - X_train: (672, 280), X_test: (168, 280)\n",
      "Sequence shapes - X_train_seq: (665, 7, 280), X_test_seq: (161, 7, 280)\n"
     ]
    }
   ],
   "source": [
    "# Data preparation\n",
    "\n",
    "# Data Preparation (data_preparation.py)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "\n",
    "def prepare_data():\n",
    "    # Create directories if they don't exist\n",
    "    Path(\"../models\").mkdir(parents=True, exist_ok=True)\n",
    "    Path(\"../data/processed\").mkdir(parents=True, exist_ok=True)\n",
    "    Path(\"../reports/figures\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Load cleaned data\n",
    "    df = pd.read_csv(\"../data/processed/cleaned_flood_data.csv\")\n",
    "\n",
    "    # Feature Engineering\n",
    "    df[\"FLOOD_OCCURRENCE\"] = (df[\"PERSONS_AFFECTED\"] > 0).astype(int)  # Binary target\n",
    "    df[\"DATE\"] = pd.to_datetime(df[\"DATE\"])\n",
    "    df[\"DAY_OF_YEAR\"] = df[\"DATE\"].dt.dayofyear\n",
    "    df[\"MONTH_SIN\"] = np.sin(2 * np.pi * df[\"DATE\"].dt.month / 12)  # Cyclical encoding\n",
    "    df[\"MONTH_COS\"] = np.cos(2 * np.pi * df[\"DATE\"].dt.month / 12)\n",
    "\n",
    "    # Define features and target\n",
    "    numeric_features = [\"DAY_OF_YEAR\", \"MONTH_SIN\", \"MONTH_COS\"]\n",
    "    categorical_features = [\"STATE\", \"LGA\", \"SEASON\"]  # Added SEASON as categorical\n",
    "\n",
    "    # Preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", StandardScaler(), numeric_features),\n",
    "            (\n",
    "                \"cat\",\n",
    "                OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
    "                categorical_features,\n",
    "            ),\n",
    "        ],\n",
    "        remainder=\"drop\",  # Drop any columns not explicitly transformed\n",
    "    )\n",
    "\n",
    "    # Split data\n",
    "    X = df[numeric_features + categorical_features]\n",
    "    y = df[\"FLOOD_OCCURRENCE\"].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Fit and transform the training data\n",
    "    print(\"Fitting preprocessor...\")\n",
    "    X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "    # Transform test data\n",
    "    X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "    # Save preprocessing objects\n",
    "    joblib.dump(preprocessor, \"../models/preprocessor.joblib\")\n",
    "    print(\"✅ Preprocessor saved to ../models/preprocessor.joblib\")\n",
    "\n",
    "    # Get feature names after preprocessing\n",
    "    numeric_feature_names = numeric_features\n",
    "    categorical_feature_names = preprocessor.named_transformers_[\n",
    "        \"cat\"\n",
    "    ].get_feature_names_out(categorical_features)\n",
    "    all_feature_names = np.concatenate(\n",
    "        [numeric_feature_names, categorical_feature_names]\n",
    "    )\n",
    "\n",
    "    # For LSTM models - reshape into sequences (assuming 7-day sequences)\n",
    "    def create_sequences(features, targets, sequence_length=7):\n",
    "        X_seq, y_seq = [], []\n",
    "        for i in range(len(features) - sequence_length):\n",
    "            X_seq.append(features[i : i + sequence_length])\n",
    "            y_seq.append(targets[i + sequence_length])\n",
    "        return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "    # Convert to sequences if using LSTM\n",
    "    X_train_seq, y_train_seq = create_sequences(X_train_preprocessed, y_train)\n",
    "    X_test_seq, y_test_seq = create_sequences(X_test_preprocessed, y_test)\n",
    "\n",
    "    # Save processed data\n",
    "    np.savez(\n",
    "        \"../data/processed/model_ready_data.npz\",\n",
    "        X_train=X_train_preprocessed,\n",
    "        X_test=X_test_preprocessed,\n",
    "        y_train=y_train,\n",
    "        y_test=y_test,\n",
    "        X_train_seq=X_train_seq,\n",
    "        y_train_seq=y_train_seq,\n",
    "        X_test_seq=X_test_seq,\n",
    "        y_test_seq=y_test_seq,\n",
    "        feature_names=all_feature_names,\n",
    "    )\n",
    "\n",
    "    print(\"✅ Data preparation complete!\")\n",
    "    print(\n",
    "        f\"Shapes - X_train: {X_train_preprocessed.shape}, X_test: {X_test_preprocessed.shape}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Sequence shapes - X_train_seq: {X_train_seq.shape}, X_test_seq: {X_test_seq.shape}\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"preprocessor_path\": \"../models/preprocessor.joblib\",\n",
    "        \"data_path\": \"../data/processed/model_ready_data.npz\",\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 115ms/step - accuracy: 0.0040 - loss: nan - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0062 - val_loss: nan - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/25\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.0063 - loss: nan - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0062 - val_loss: nan - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/25\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.0043 - loss: nan - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0062 - val_loss: nan - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/25\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.0037 - loss: nan - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0062 - val_loss: nan - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/25\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.0033 - loss: nan - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0062 - val_loss: nan - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/25\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 0.0032 - loss: nan - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0062 - val_loss: nan - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/25\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.0024 - loss: nan - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0062 - val_loss: nan - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/25\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.0046 - loss: nan - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0062 - val_loss: nan - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/25\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.0053 - loss: nan - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0062 - val_loss: nan - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/25\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.0023 - loss: nan - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0062 - val_loss: nan - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/25\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.0086 - loss: nan - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0062 - val_loss: nan - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 159ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# LSTM Model Implementation for Flood Prediction\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Setup directories\n",
    "Path(\"../models\").mkdir(exist_ok=True)\n",
    "Path(\"../reports/figures\").mkdir(exist_ok=True)\n",
    "\n",
    "# Load data\n",
    "data = np.load(\"../data/processed/model_ready_data.npz\")\n",
    "X_train, y_train = data[\"X_train_seq\"], data[\"y_train_seq\"]\n",
    "X_test, y_test = data[\"X_test_seq\"], data[\"y_test_seq\"]\n",
    "\n",
    "\n",
    "# LSTM Model\n",
    "# Update model compilation:\n",
    "def build_lstm(input_shape):\n",
    "    model = Sequential(\n",
    "        [\n",
    "            LSTM(128, input_shape=input_shape, return_sequences=True),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.3),\n",
    "            LSTM(64, return_sequences=False),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.3),\n",
    "            Dense(1, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=Adam(0.001),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\n",
    "            \"accuracy\",\n",
    "            tf.keras.metrics.Precision(name=\"precision\"),  # Training precision\n",
    "            tf.keras.metrics.Recall(name=\"recall\"),  # Training recall\n",
    "        ],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# Train & evaluate\n",
    "lstm = build_lstm((X_train.shape[1], X_train.shape[2]))\n",
    "history = lstm.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=25,\n",
    "    batch_size=32,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=10, restore_best_weights=True),\n",
    "        ModelCheckpoint(\"../models/lstm_best.keras\", save_best_only=True),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Compute metrics manually (since val_precision/val_recall won't be auto-tracked)\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "y_pred = (lstm.predict(X_test) > 0.5).astype(int)\n",
    "metrics = {\n",
    "    \"accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"precision\": precision_score(y_test, y_pred),\n",
    "    \"recall\": recall_score(y_test, y_pred),\n",
    "}\n",
    "joblib.dump(metrics, \"../models/lstm_metrics.joblib\")\n",
    "\n",
    "# Plot training\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Train\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Validation\")\n",
    "plt.title(\"LSTM Training History\")\n",
    "plt.savefig(\"../reports/figures/lstm_history.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 68ms/step - accuracy: 0.0058 - loss: nan - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0062 - val_loss: nan - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.0067 - loss: nan - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0062 - val_loss: nan - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0018 - loss: nan - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0062 - val_loss: nan - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0052 - loss: nan - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0062 - val_loss: nan - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.0025 - loss: nan - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0062 - val_loss: nan - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.0016 - loss: nan - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0062 - val_loss: nan - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.0041 - loss: nan - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0062 - val_loss: nan - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.0040 - loss: nan - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0062 - val_loss: nan - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0034 - loss: nan - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0062 - val_loss: nan - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0119 - loss: nan - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0062 - val_loss: nan - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.0032 - loss: nan - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0062 - val_loss: nan - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raheeminioluwa/Documents/Flood-EDA-Nigeria/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/cnn_metrics.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN Model Implementation for Flood Prediction\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "data = np.load(\"../data/processed/model_ready_data.npz\")\n",
    "X_train, y_train = data[\"X_train_seq\"], data[\"y_train_seq\"]\n",
    "X_test, y_test = data[\"X_test_seq\"], data[\"y_test_seq\"]\n",
    "\n",
    "\n",
    "# CNN Model\n",
    "def build_cnn(input_shape):\n",
    "    model = Sequential(\n",
    "        [\n",
    "            Conv1D(\n",
    "                64, 2, activation=\"relu\", input_shape=input_shape, padding=\"same\"\n",
    "            ),  # kernel_size=2\n",
    "            BatchNormalization(),\n",
    "            MaxPooling1D(2),\n",
    "            Dropout(0.3),\n",
    "            Conv1D(128, 2, activation=\"relu\", padding=\"same\"),  # kernel_size=2\n",
    "            BatchNormalization(),\n",
    "            MaxPooling1D(2),\n",
    "            Dropout(0.3),\n",
    "            Flatten(),\n",
    "            Dense(64, activation=\"relu\"),\n",
    "            Dense(1, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(0.001),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\n",
    "            \"accuracy\",\n",
    "            tf.keras.metrics.Precision(name=\"precision\"),  # Training precision\n",
    "            tf.keras.metrics.Recall(name=\"recall\"),  # Training recall\n",
    "        ],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# Train\n",
    "cnn = build_cnn((X_train.shape[1], X_train.shape[2]))\n",
    "history = cnn.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=10),\n",
    "        ModelCheckpoint(\"../models/cnn_best.keras\", save_best_only=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Save\n",
    "cnn.save(\"../models/cnn_final.keras\")\n",
    "metrics = {\n",
    "    \"accuracy\": history.history[\"val_accuracy\"][-1],\n",
    "    \"precision\": precision_score(y_test, y_pred),\n",
    "    \"recall\": recall_score(y_test, y_pred),\n",
    "}\n",
    "joblib.dump(metrics, \"../models/cnn_metrics.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 796ms/step - accuracy: 0.0315 - loss: nan - val_accuracy: 0.0062 - val_loss: nan\n",
      "Epoch 2/7\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 507ms/step - accuracy: 0.0015 - loss: nan - val_accuracy: 0.0062 - val_loss: nan\n",
      "Epoch 3/7\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 474ms/step - accuracy: 0.0039 - loss: nan - val_accuracy: 0.0062 - val_loss: nan\n",
      "Epoch 4/7\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 480ms/step - accuracy: 0.0014 - loss: nan - val_accuracy: 0.0062 - val_loss: nan\n",
      "Epoch 5/7\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 722ms/step - accuracy: 0.0057 - loss: nan - val_accuracy: 0.0062 - val_loss: nan\n",
      "Epoch 6/7\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 538ms/step - accuracy: 0.0090 - loss: nan - val_accuracy: 0.0062 - val_loss: nan\n",
      "Epoch 7/7\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 509ms/step - accuracy: 0.0034 - loss: nan - val_accuracy: 0.0062 - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Conv1D,\n",
    "    MaxPooling1D,\n",
    "    LSTM,\n",
    "    Dense,\n",
    "    TimeDistributed,\n",
    "    Flatten,\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Load data\n",
    "data = np.load(\"../data/processed/model_ready_data.npz\")\n",
    "X_train = data[\"X_train_seq\"].reshape(*data[\"X_train_seq\"].shape, 1)\n",
    "y_train = data[\"y_train_seq\"]\n",
    "X_test = data[\"X_test_seq\"].reshape(*data[\"X_test_seq\"].shape, 1)\n",
    "y_test = data[\"y_test_seq\"]\n",
    "\n",
    "\n",
    "# Hybrid Model\n",
    "def build_hybrid(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # CNN Branch\n",
    "    x = TimeDistributed(Conv1D(64, 3, activation=\"relu\"))(inputs)\n",
    "    x = TimeDistributed(MaxPooling1D(2))(x)\n",
    "    x = TimeDistributed(Flatten())(x)\n",
    "\n",
    "    # LSTM Branch\n",
    "    x = LSTM(64)(x)\n",
    "    outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Train\n",
    "hybrid = build_hybrid((X_train.shape[1], X_train.shape[2], 1))\n",
    "hybrid.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=7, batch_size=32)\n",
    "\n",
    "hybrid.save(\"../models/hybrid_final.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance Comparison:\n",
      "      accuracy  precision  recall\n",
      "LSTM  0.006211        0.0     0.0\n",
      "CNN   0.006211        0.0     0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load metrics\n",
    "metrics = {\n",
    "    \"LSTM\": joblib.load(\"../models/lstm_metrics.joblib\"),\n",
    "    \"CNN\": joblib.load(\"../models/cnn_metrics.joblib\"),\n",
    "    # \"Hybrid\": joblib.load(\"../models/hybrid_metrics.joblib\"),\n",
    "}\n",
    "\n",
    "# Create comparison table\n",
    "df = pd.DataFrame(metrics).T\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(df)\n",
    "\n",
    "# Plot comparison\n",
    "df.plot(kind=\"bar\", figsize=(10, 6))\n",
    "plt.title(\"Model Comparison\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0, 1)\n",
    "plt.savefig(\"../reports/figures/model_comparison.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
